{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84795,"databundleVersionId":10821240,"sourceType":"competition"},{"sourceId":3623845,"sourceType":"datasetVersion","datasetId":2171258},{"sourceId":162822,"sourceType":"modelInstanceVersion","modelInstanceId":138458,"modelId":161088},{"sourceId":169042,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":143819,"modelId":166403}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A minimal soltion to the problem by creating solver agents","metadata":{}},{"cell_type":"code","source":"!pip install accelerate\n!pip install einops\n#!pip install - U bitsandbytes\n!pip install transformers_stream_generator==0.0.4\n#!pip install -U --no-index --find-links=/kaggle/input/vllm-whl -U vllm\n#!pip install -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n#!pip install -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\n#https://www.kaggle.com/code/tranhoangquan/aimo-ss2-quan/notebook\n!unzip -nq ../input/konwinski-prize/data.a_zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:57:16.227897Z","iopub.execute_input":"2025-01-21T11:57:16.228211Z","iopub.status.idle":"2025-01-21T12:00:50.028696Z","shell.execute_reply.started":"2025-01-21T11:57:16.228175Z","shell.execute_reply":"2025-01-21T12:00:50.027497Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78086599b730>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers-stream-generator/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78086599bac0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers-stream-generator/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78086599bdf0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers-stream-generator/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78086599bfd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers-stream-generator/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7808657d01f0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers-stream-generator/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement transformers_stream_generator==0.0.4 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for transformers_stream_generator==0.0.4\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom typing import List\nfrom transformers import AutoModelForCausalLM, AutoTokenizer,AutoModel\nfrom transformers import RobertaTokenizer, RobertaModel\nimport io\nimport os\nimport shutil\nfrom pathlib import Path\nimport fnmatch\nfrom git import Repo\nimport subprocess\nimport gc\nimport kaggle_evaluation.konwinski_prize_inference_server\nimport numpy as np\nfrom difflib import SequenceMatcher\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom datetime import datetime\ntrain_data = pd.read_parquet(\"/kaggle/working/data/data.parquet\")\ntrain_data['instance_id'] = \"repo__\" + train_data['instance_id'] \n#train_data['path'] =train_data['instance_id'] + \"/\" + train_data['instance_id'] \n#train_data['path_exists'] = train_data['path'].apply(lambda x: os.path.exists(x))\ntrain_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:00:50.029810Z","iopub.execute_input":"2025-01-21T12:00:50.030160Z","iopub.status.idle":"2025-01-21T12:01:01.713034Z","shell.execute_reply.started":"2025-01-21T12:00:50.030138Z","shell.execute_reply":"2025-01-21T12:01:01.712052Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                      instance_id                repo  \\\n0  repo__pylint-dev__astroid-2496  pylint-dev/astroid   \n1  repo__pylint-dev__astroid-2468  pylint-dev/astroid   \n2    repo__astropy__astropy-17048     astropy/astropy   \n3    repo__astropy__astropy-16898     astropy/astropy   \n4    repo__astropy__astropy-16830     astropy/astropy   \n5    repo__astropy__astropy-16812     astropy/astropy   \n\n                                   problem_statement  \\\n0  TypeError: unsupported format string passed to...   \n1  Pylint checks against incorrect type with prop...   \n2  QTable cannot take `dimensionless_unscaled` wh...   \n3  BUG: tables do not deal well with zero-sized s...   \n4  KeyError: 'version_1_3_or_later' when parsing ...   \n5  Provide a way to make a copy of a model with d...   \n\n                                               patch  \\\n0  diff --git a/ChangeLog b/ChangeLog\\nindex 4560...   \n1  diff --git a/ChangeLog b/ChangeLog\\nindex fdbb...   \n2  diff --git a/astropy/table/table.py b/astropy/...   \n3  diff --git a/astropy/io/registry/core.py b/ast...   \n4  diff --git a/astropy/io/votable/tree.py b/astr...   \n5  diff --git a/astropy/modeling/core.py b/astrop...   \n\n                                          test_patch  pull_number  \\\n0  diff --git a/tests/test_inference.py b/tests/t...         2496   \n1  diff --git a/tests/test_inference.py b/tests/t...         2468   \n2  diff --git a/astropy/table/tests/test_table.py...        17048   \n3  diff --git a/astropy/io/fits/tests/test_connec...        16898   \n4  diff --git a/astropy/io/votable/tests/test_tre...        16830   \n5  diff --git a/astropy/modeling/tests/test_core....        16812   \n\n                                base_commit  \\\n0  8d3cdbbe6685fd8cf211816bec56c90f38f1859e   \n1  6db3a60553ff538a936d5dda23d67a3924a57f45   \n2  d60f6b72cd525262bfd179331d9fe4474177918f   \n3  ee6d087baf301c1d08db92e6e5b6d909d57e6fac   \n4  e39f486fec48d87aa3677326167954370d7a7bf9   \n5  c241103c11954d3c1cfe3c1840b1ece72479c522   \n\n                                        PASS_TO_PASS  \\\n0  [tests/test_inference.py::InferenceUtilsTest::...   \n1  [tests/test_inference.py::InferenceUtilsTest::...   \n2  [astropy/table/tests/test_table.py::TestSetTab...   \n3  [astropy/io/fits/tests/test_connect.py::TestSi...   \n4  [astropy/io/votable/tests/test_tree.py::test_c...   \n5  [astropy/modeling/tests/test_core.py::test_Mod...   \n\n                                        FAIL_TO_PASS   issue_numbers  \n0  [tests/test_inference.py::test_formatted_fstri...          [2492]  \n1  [tests/test_inference.py::InferenceTest::test_...          [2467]  \n2  [astropy/table/tests/test_table.py::test_qtabl...         [17047]  \n3  [astropy/io/fits/tests/test_connect.py::test_z...         [16897]  \n4  [astropy/io/votable/tests/test_tree.py::test_v...  [16825, 16826]  \n5  [astropy/modeling/tests/test_core.py::test_res...         [16593]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instance_id</th>\n      <th>repo</th>\n      <th>problem_statement</th>\n      <th>patch</th>\n      <th>test_patch</th>\n      <th>pull_number</th>\n      <th>base_commit</th>\n      <th>PASS_TO_PASS</th>\n      <th>FAIL_TO_PASS</th>\n      <th>issue_numbers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>repo__pylint-dev__astroid-2496</td>\n      <td>pylint-dev/astroid</td>\n      <td>TypeError: unsupported format string passed to...</td>\n      <td>diff --git a/ChangeLog b/ChangeLog\\nindex 4560...</td>\n      <td>diff --git a/tests/test_inference.py b/tests/t...</td>\n      <td>2496</td>\n      <td>8d3cdbbe6685fd8cf211816bec56c90f38f1859e</td>\n      <td>[tests/test_inference.py::InferenceUtilsTest::...</td>\n      <td>[tests/test_inference.py::test_formatted_fstri...</td>\n      <td>[2492]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>repo__pylint-dev__astroid-2468</td>\n      <td>pylint-dev/astroid</td>\n      <td>Pylint checks against incorrect type with prop...</td>\n      <td>diff --git a/ChangeLog b/ChangeLog\\nindex fdbb...</td>\n      <td>diff --git a/tests/test_inference.py b/tests/t...</td>\n      <td>2468</td>\n      <td>6db3a60553ff538a936d5dda23d67a3924a57f45</td>\n      <td>[tests/test_inference.py::InferenceUtilsTest::...</td>\n      <td>[tests/test_inference.py::InferenceTest::test_...</td>\n      <td>[2467]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>repo__astropy__astropy-17048</td>\n      <td>astropy/astropy</td>\n      <td>QTable cannot take `dimensionless_unscaled` wh...</td>\n      <td>diff --git a/astropy/table/table.py b/astropy/...</td>\n      <td>diff --git a/astropy/table/tests/test_table.py...</td>\n      <td>17048</td>\n      <td>d60f6b72cd525262bfd179331d9fe4474177918f</td>\n      <td>[astropy/table/tests/test_table.py::TestSetTab...</td>\n      <td>[astropy/table/tests/test_table.py::test_qtabl...</td>\n      <td>[17047]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>repo__astropy__astropy-16898</td>\n      <td>astropy/astropy</td>\n      <td>BUG: tables do not deal well with zero-sized s...</td>\n      <td>diff --git a/astropy/io/registry/core.py b/ast...</td>\n      <td>diff --git a/astropy/io/fits/tests/test_connec...</td>\n      <td>16898</td>\n      <td>ee6d087baf301c1d08db92e6e5b6d909d57e6fac</td>\n      <td>[astropy/io/fits/tests/test_connect.py::TestSi...</td>\n      <td>[astropy/io/fits/tests/test_connect.py::test_z...</td>\n      <td>[16897]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>repo__astropy__astropy-16830</td>\n      <td>astropy/astropy</td>\n      <td>KeyError: 'version_1_3_or_later' when parsing ...</td>\n      <td>diff --git a/astropy/io/votable/tree.py b/astr...</td>\n      <td>diff --git a/astropy/io/votable/tests/test_tre...</td>\n      <td>16830</td>\n      <td>e39f486fec48d87aa3677326167954370d7a7bf9</td>\n      <td>[astropy/io/votable/tests/test_tree.py::test_c...</td>\n      <td>[astropy/io/votable/tests/test_tree.py::test_v...</td>\n      <td>[16825, 16826]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>repo__astropy__astropy-16812</td>\n      <td>astropy/astropy</td>\n      <td>Provide a way to make a copy of a model with d...</td>\n      <td>diff --git a/astropy/modeling/core.py b/astrop...</td>\n      <td>diff --git a/astropy/modeling/tests/test_core....</td>\n      <td>16812</td>\n      <td>c241103c11954d3c1cfe3c1840b1ece72479c522</td>\n      <td>[astropy/modeling/tests/test_core.py::test_Mod...</td>\n      <td>[astropy/modeling/tests/test_core.py::test_res...</td>\n      <td>[16593]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:01.713961Z","iopub.execute_input":"2025-01-21T12:01:01.714406Z","iopub.status.idle":"2025-01-21T12:01:01.737254Z","shell.execute_reply.started":"2025-01-21T12:01:01.714383Z","shell.execute_reply":"2025-01-21T12:01:01.736661Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6 entries, 0 to 5\nData columns (total 10 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   instance_id        6 non-null      object\n 1   repo               6 non-null      object\n 2   problem_statement  6 non-null      object\n 3   patch              6 non-null      object\n 4   test_patch         6 non-null      object\n 5   pull_number        6 non-null      int64 \n 6   base_commit        6 non-null      object\n 7   PASS_TO_PASS       6 non-null      object\n 8   FAIL_TO_PASS       6 non-null      object\n 9   issue_numbers      6 non-null      object\ndtypes: int64(1), object(9)\nmemory usage: 608.0+ bytes\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train_data.sample()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:01.737880Z","iopub.execute_input":"2025-01-21T12:01:01.738070Z","iopub.status.idle":"2025-01-21T12:01:01.763038Z","shell.execute_reply.started":"2025-01-21T12:01:01.738055Z","shell.execute_reply":"2025-01-21T12:01:01.762194Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                    instance_id             repo  \\\n5  repo__astropy__astropy-16812  astropy/astropy   \n\n                                   problem_statement  \\\n5  Provide a way to make a copy of a model with d...   \n\n                                               patch  \\\n5  diff --git a/astropy/modeling/core.py b/astrop...   \n\n                                          test_patch  pull_number  \\\n5  diff --git a/astropy/modeling/tests/test_core....        16812   \n\n                                base_commit  \\\n5  c241103c11954d3c1cfe3c1840b1ece72479c522   \n\n                                        PASS_TO_PASS  \\\n5  [astropy/modeling/tests/test_core.py::test_Mod...   \n\n                                        FAIL_TO_PASS issue_numbers  \n5  [astropy/modeling/tests/test_core.py::test_res...       [16593]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instance_id</th>\n      <th>repo</th>\n      <th>problem_statement</th>\n      <th>patch</th>\n      <th>test_patch</th>\n      <th>pull_number</th>\n      <th>base_commit</th>\n      <th>PASS_TO_PASS</th>\n      <th>FAIL_TO_PASS</th>\n      <th>issue_numbers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>repo__astropy__astropy-16812</td>\n      <td>astropy/astropy</td>\n      <td>Provide a way to make a copy of a model with d...</td>\n      <td>diff --git a/astropy/modeling/core.py b/astrop...</td>\n      <td>diff --git a/astropy/modeling/tests/test_core....</td>\n      <td>16812</td>\n      <td>c241103c11954d3c1cfe3c1840b1ece72479c522</td>\n      <td>[astropy/modeling/tests/test_core.py::test_Mod...</td>\n      <td>[astropy/modeling/tests/test_core.py::test_res...</td>\n      <td>[16593]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model_path = \"/kaggle/input/codebert-base/codebert-base\"\ntokenizer = RobertaTokenizer.from_pretrained(\n    model_path,\n    local_files_only=True,\n    vocab_file=os.path.join(model_path, \"vocab.json\"),\n    merges_file=os.path.join(model_path, \"merges.txt\")\n)\n\nmodel = RobertaModel.from_pretrained(\n    model_path,\n    local_files_only=True,\n    config=os.path.join(model_path, \"config.json\"),\n    state_dict=torch.load(os.path.join(model_path, \"pytorch_model.bin\"))\n)\n\ndef calculate_semantic_similarity(pred: str, truth: str, model, tokenizer) -> float:\n    inputs = tokenizer([pred, truth], \n                      padding=True, \n                      truncation=True, \n                      max_length=512, \n                      return_tensors=\"pt\").to(model.device)\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    attention_mask = inputs.attention_mask.unsqueeze(-1)\n    embeddings = (outputs.last_hidden_state * attention_mask).sum(dim=1) / attention_mask.sum(dim=1).clamp(min=1e-9)\n    \n    return cosine_similarity(embeddings[0].cpu().numpy().reshape(1, -1), \n                            embeddings[1].cpu().numpy().reshape(1, -1))[0][0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:01.763811Z","iopub.execute_input":"2025-01-21T12:01:01.764004Z","iopub.status.idle":"2025-01-21T12:01:05.848632Z","shell.execute_reply.started":"2025-01-21T12:01:01.763988Z","shell.execute_reply":"2025-01-21T12:01:05.847772Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n<ipython-input-5-f255b806e940>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict=torch.load(os.path.join(model_path, \"pytorch_model.bin\"))\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def find_most_related_file(text_input, repo_dir, top_n=1, max_file_size=4000):\n    code_files = []\n    for root, _, files in os.walk(repo_dir):\n        for file in files:\n            if file.endswith(('.py', '.java', '.cpp', '.js', '.ts', '.c', '.h')):\n                filepath = os.path.join(root, file)\n                try:\n                    # Check file size\n                    if os.path.getsize(filepath) > max_file_size * 1024:  # Convert KB to bytes\n                        continue\n                    \n                    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n                    code_files.append((filepath, content))\n                except Exception as e:\n                    print(f\"Error reading file {filepath}: {e}\")\n    \n    if not code_files:\n        print(\"No code files found in the repository directory.\")\n        return []\n    code_df = pd.DataFrame(code_files, columns=['file_path', 'file_content'])\n    \n    file_contents = code_df['file_content'].values.astype(str).tolist()\n    all_texts = [str(text_input)] + file_contents  # Ensure text_input is also a string\n    \n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(all_texts)\n    \n    text_vector = tfidf_matrix[0]\n    file_vectors = tfidf_matrix[1:]\n    similarity_scores = cosine_similarity(text_vector, file_vectors).flatten()\n    \n    top_indices = similarity_scores.argsort()[-top_n:][::-1]\n    top_files = [code_df.iloc[i]['file_path'] for i in top_indices]\n    return top_files\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:05.850888Z","iopub.execute_input":"2025-01-21T12:01:05.851104Z","iopub.status.idle":"2025-01-21T12:01:05.859728Z","shell.execute_reply.started":"2025-01-21T12:01:05.851086Z","shell.execute_reply":"2025-01-21T12:01:05.858953Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#Function to summarize the repo\ndef get_repo_structure_fallback(repo_path: str, max_depth: int = 3) -> str:\n    \"\"\"Recursive directory structure listing\"\"\"\n    structure = []\n    \n    def _walk(path: Path, current_depth: int):\n        if current_depth > max_depth:\n            return\n            \n        # Add directory entry\n        dir_entry = f\"{'  ' * (current_depth-1)}ðŸ“ {path.name}/\"\n        structure.append(dir_entry)\n        \n        # List files first\n        files = sorted([f for f in path.iterdir() if f.is_file()])\n        for f in files[:5]:  # Limit files per directory\n            structure.append(f\"{'  ' * current_depth}ðŸ“„ {f.name}\")\n            \n        # Recursively list directories\n        dirs = sorted([d for d in path.iterdir() if d.is_dir() \n                      and d.name not in ['.git', '__pycache__', 'node_modules']])\n        for d in dirs[:5]:  # Limit subdirectories\n            _walk(d, current_depth + 1)\n    \n    try:\n        _walk(Path(repo_path), 1)\n        return \"\\n\".join(structure)[:2000]  # Truncate long outputs\n    except Exception as e:\n        return f\"Error generating structure: {str(e)}\"\ndef get_git_aware_structure(repo_path: str) -> str:\n    \"\"\"Get structure with git history insights\"\"\"\n    structure = []\n    repo = Repo(repo_path)\n    \n    # Get recent authors\n    contributors = set()\n    for commit in repo.iter_commits('HEAD', max_count=10):\n        contributors.add(commit.author.name)\n    \n    # Get modified files\n    modified = [item.a_path for item in repo.index.diff(None)]\n    \n    # Build structure\n    structure.append(f\"Recent contributors: {', '.join(contributors)[:100]}\")\n    structure.append(\"Recent modified files:\")\n    structure.extend(modified[:10])\n    \n    return \"\\n\".join(structure)\n    \ndef identify_important_files(repo_path: str) -> str:\n    \"\"\"Identify likely important files\"\"\"\n    priority_files = []\n    \n    # Common important file patterns\n    important_patterns = [\n        'requirements.txt', 'setup.py', 'package.json',\n        'Dockerfile', 'Makefile', '*.md',\n        'src/', 'lib/', 'main.py', 'app.py'\n    ]\n    \n    for root, _, files in os.walk(repo_path):\n        for f in files:\n            path = Path(root) / f\n            rel_path = path.relative_to(repo_path)\n            \n            # Check against known patterns\n            if any(fnmatch.fnmatch(str(rel_path), pat) for pat in important_patterns):\n                priority_files.append(f\"* {rel_path}\")\n                \n            # Check file size\n            if path.stat().st_size > 100000:  # >100KB\n                priority_files.append(rel_path)\n    \n    return priority_files[:20]\ndef analyze_repo_structure(repo_path: str) -> str:\n    \"\"\"Combine multiple structure analysis methods\"\"\"\n    parts = []\n    \n    # Basic directory structure\n    parts.append(\"## Directory Structure ##\")\n    parts.append(get_repo_structure_fallback(repo_path))\n    \n    # Important files analysis\n    parts.append(\"\\n## Key Files ##\")\n    parts.append(identify_important_files(repo_path))\n    \n    # Git insights\n    try:\n        parts.append(\"\\n## Development Insights ##\")\n        parts.append(get_git_aware_structure(repo_path))\n    except:\n        pass\n    \n    return parts\n#analyze_repo_structure(repo_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:05.861507Z","iopub.execute_input":"2025-01-21T12:01:05.861751Z","iopub.status.idle":"2025-01-21T12:01:05.878420Z","shell.execute_reply.started":"2025-01-21T12:01:05.861731Z","shell.execute_reply":"2025-01-21T12:01:05.877820Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def cosine_similarity_reviews(text1, text2):\n    # Combine the two reviews into a list\n    reviews = [text1, text2]\n    \n    # Step 1: Compute TF-IDF embeddings for both reviews\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(reviews)\n    \n    # Step 2: Calculate cosine similarity\n    similarity_score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n    \n    return similarity_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:05.879178Z","iopub.execute_input":"2025-01-21T12:01:05.879443Z","iopub.status.idle":"2025-01-21T12:01:05.897682Z","shell.execute_reply.started":"2025-01-21T12:01:05.879424Z","shell.execute_reply":"2025-01-21T12:01:05.896997Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#Example Usage\ntext_input = train_data['problem_statement'].values[4]\nprint(\"issue: \", text_input[:200])\nrepo_dir = \"/kaggle/working/data/repos\"\nprint(datetime.now().strftime(\"Hour: %H, Minute: %M, Second: %S\"))\ntop_related_file = find_most_related_file(text_input, repo_dir, top_n=1)\nprint(datetime.now().strftime(\"Hour: %H, Minute: %M, Second: %S\"))\nfor file_path in top_related_file:\n        print(f\"File: {file_path}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:05.898415Z","iopub.execute_input":"2025-01-21T12:01:05.898761Z","iopub.status.idle":"2025-01-21T12:01:38.575129Z","shell.execute_reply.started":"2025-01-21T12:01:05.898699Z","shell.execute_reply":"2025-01-21T12:01:38.574366Z"}},"outputs":[{"name":"stdout","text":"issue:  KeyError: 'version_1_3_or_later' when parsing certain VOTables\n### Description\n\nWhen parsing VOTables (for instance) VOTables with empty integer literals in some places (e.g., MIN value=\"\" in a VALUES\nHour: 12, Minute: 01, Second: 05\nHour: 12, Minute: 01, Second: 38\nFile: /kaggle/working/data/repos/repo__astropy__astropy-17048/astropy/table/tests/conftest.py\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()\n#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512,garbage_collection_threshold:0.8,expandable_segments:True\"\n\nclass GithubIssueSolver:\n    def __init__(self):\n        model_name = \"/kaggle/input/qwen2.5-coder/transformers/7b-instruct/1\"#\n        \n        # More conservative memory settings\n        #max_memory = {0: \"12GiB\", \"cpu\": \"12GiB\"}\n        \n        self.model = AutoModelForCausalLM.from_pretrained(\n            model_name,\n            torch_dtype=torch.float16,\n            device_map=\"auto\",\n            #max_memory=max_memory,\n            low_cpu_mem_usage=True,\n            offload_folder=\"offload\",\n        )\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.max_context_length = 16384  # Reduced from 4096\n        self.max_file_size = 2000  # Reduced from 1000\n    def _create_prompt(self, problem_statement: str, context: str, repo_structure: str) -> str:\n        return f\"\"\"**Task**: Fix the GitHub issue by generating a correct git diff patch. Use strict step-by-step reasoning.\n    \n                **Format Requirements**:\n                1. Output MUST start with 'diff --git'\n                2. Only modify relevant files (max 3 files)\n                3. Include precise line numbers\n                4. Never write code comments unless present in original\n                5. Include only necessary changes\n                \n                **Problem Analysis Framework**:\n                1. Root Cause Identification:\n                   - Identify specific components causing the issue\n                   - Analyze error patterns from problem description\n                \n                2. Code Context Mapping:\n                   - Match issue components to relevant code sections\n                   - File structure: {repo_structure}\n                   - Relevant code snippets: {context[:5000]}\n                \n                3. Change Validation:\n                   - Cross-verify each change against problem statement\n                   - Ensure no unrelated code modifications\n                \n                **Example of Good Patch**:\n                diff --git a/file.py b/file.py\n                --- a/file.py\n                +++ b/file.py\n                @@ -12,7 +12,7 @@\n                     try:\n                -        result = process(data)\n                +        result = process(data, timeout=30)\n                     except TimeoutError:\n                -        logger.warning(\"Timeout occurred\")\n                +        logger.error(\"Timeout (30s) exceeded\", exc_info=True)\n                \n                **Current Issue**:\n                {problem_statement[:5000]}\n                \n                **Step-by-Step Process**:\n                1. Identify key components needing modification\n                2. Locate exact lines in relevant files\n                3. Make minimal changes to fix issue\n                4. Verify against all mentioned edge cases\n                \n                **Output Instructions**:\n                - Start immediately with diff patch\n                - Use exact file paths from repository\n                - Include confidence score (0-100) as last line\n                - If uncertain, output \"SKIP\" with reason\n                \n                **Begin Fix**:\n                \"\"\"\n    def analyze_issue(self, problem_statement: str, repo_path: str) -> str:\n        try:\n            torch.cuda.empty_cache()\n            gc.collect()\n            \n            relevant_files = self._find_relevant_files(repo_path, problem_statement)\n            if not relevant_files:\n                print(\"No relevant files found\")\n                return None\n                \n            context = self._read_file_contents(repo_path, relevant_files)\n            repo_structure = analyze_repo_structure(repo_path)\n            prompt= self._create_prompt(problem_statement, context, repo_structure)\n            #modified CoT prompt from: https://arxiv.org/pdf/2501.05040\n            messages = [\n                {\"role\": \"system\", \"content\": \"\"\"\"\n                                    You are an expert software engineer and code reviewer specializing in resolving real-world GitHub issues by creating precise diff patches. Your role is to analyze the issue description and the most relevant code segments from the repository (pre-identified using cosine similarity) to propose effective and accurate code modifications.\n                                    \n                                    In this task, you will:\n                                    \n                                    1. **Understand the Issue:** Carefully analyze the provided GitHub issue description to identify the root cause and the functional or structural problem in the code.\n                                    2. **Analyze Relevant Code:** Examine the provided code snippets or files identified as most relevant to the issue. Use your expertise to determine the exact areas requiring modification.\n                                    3. **Generate a Diff Patch:** Create a detailed and well-structured diff patch that resolves the issue while maintaining the integrity and functionality of the codebase.\n                                    4. **Provide Reasoning:** Accompany your patch with a clear, step-by-step explanation of your reasoning process, detailing how the proposed changes address the issue effectively.\n                                    \n                                    ### Guidelines:\n                                    - **Independent Reasoning:** Your analysis and diff patch should be based solely on the issue description and the provided code snippets. Avoid referencing external solutions or implying prior knowledge of oracle modifications.\n                                    - **Clarity and Precision:** Ensure that your diff patch is syntactically correct, adheres to best coding practices, and is easy to apply.\n                                    - **Evidence-Based Reasoning:** Clearly justify your changes, linking them to specific parts of the issue description and code. Highlight how the modifications resolve the issue and improve the codebase.\n                                    \n                                    This task focuses on accurately resolving GitHub issues through diff patches while maintaining high standards of clarity, precision, and logical consistency.\n                                                \"\"\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            text = self.tokenizer.apply_chat_template(\n                messages,\n                tokenize=False,\n                add_generation_prompt=True\n            )\n            \n            # Split processing into smaller chunks\n            inputs = self.tokenizer(\n                text, \n                return_tensors=\"pt\", \n                truncation=True,\n                max_length=self.max_context_length\n            ).to(self.model.device)\n            \n            with torch.inference_mode():\n                try:\n                    generated_ids = self.model.generate(\n                        input_ids=inputs['input_ids'],\n                        max_new_tokens=16384,  # Reduced from 1024\n                        temperature=0.8,#from 0.7\n                        do_sample=True,\n                        pad_token_id=self.tokenizer.pad_token_id,\n                        num_return_sequences=1,\n                    )\n                    \n                    response = self.tokenizer.decode(\n                        generated_ids[0, inputs['input_ids'].shape[1]:],\n                        skip_special_tokens=True\n                    )\n                finally:\n                    del inputs\n                    torch.cuda.empty_cache()\n                    gc.collect()\n            \n            if \"diff --git\" in response:\n                diff_start = response.find(\"diff --git\")\n                return response[diff_start:]\n            return None\n            \n        except Exception as e:\n            print(f\"Error generating solution: {str(e)}\")\n            return None\n        finally:\n            torch.cuda.empty_cache()\n            gc.collect()\n\n    def _find_relevant_files(self, repo_path: str, problem_statement: str) -> list:\n        relevant_files = []\n        #relevant_files = find_most_related_file(problem_statement, repo_path, top_n=2)\n        #print(\"type(repo_path): \", type(repo_path))\n        #print(\"repo_path: \", repo_path)\n        #print(\"relevant_files: \", relevant_files[:4])\n        try:\n            keywords = set(problem_statement.lower().split())\n            #print(\"keywords: \", keywords[:25])\n            for root, _, files in os.walk(repo_path):\n                if len(relevant_files) >= 2:\n                    break\n                    \n                for file in files:\n                    if file.endswith(('.py', '.java', '.cpp', '.h', '.c', '.js', '.ts')):\n                        file_path = os.path.join(root, file)\n                        try:\n                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                                content = f.read(self.max_file_size * 50)  # Read with size limit\n                                \n                            if any(word in content.lower() for word in keywords):\n                                relevant_files.append(os.path.relpath(file_path, repo_path))\n                                if len(relevant_files) >= 2:\n                                    break\n                        except Exception:\n                            continue\n                                \n        except Exception as e:\n            print(f\"Error finding relevant files: {str(e)}\")\n      \n        print(\"num of relevant files\",  len(relevant_files))\n        print(\"relevant files\",  relevant_files)\n        return relevant_files\n\n    def _read_file_contents(self, repo_path: str, files: list) -> str:\n        contents = []\n        total_lines = 0\n        \n        for file in files:\n            if total_lines >= self.max_file_size:\n                break\n                \n            try:\n                with open(os.path.join(repo_path, file), 'r', encoding='utf-8', errors='ignore') as f:\n                    lines = []\n                    for i, line in enumerate(f):\n                        if i >= self.max_file_size // len(files):\n                            break\n                        lines.append(line)\n                    contents.append(f\"File: {file}\\n{''.join(lines)}\")\n                    total_lines += len(lines)\n            except Exception:\n                continue\n        print(\"file content: \", \"\\n\".join(contents)[:200])\n        return \"\\n\".join(contents)\n\n# Global solver instance\nsolver = None\n\ndef get_number_of_instances(num_instances: int) -> None:\n    global instance_count\n    instance_count = num_instances\n\ndef predict(\n    problem_statement: str, \n    repo_archive: io.BytesIO, \n    pip_packages_archive: io.BytesIO, \n    env_setup_cmds_templates: list[str]\n) -> str:\n    global solver\n    \n    # Define repo_path at the start\n    repo_path = os.path.join(os.getcwd(), 'repo')\n    \n    try:\n        if solver is None:\n            solver = GithubIssueSolver()\n        \n        # Clean up any existing repo directory\n        if os.path.exists(repo_path):\n            shutil.rmtree(repo_path)\n        \n        # Create archive file and extract\n        archive_path = os.path.join(os.getcwd(), 'repo_archive.tar')\n        with open(archive_path, 'wb') as f:\n            f.write(repo_archive.read())\n            \n        os.makedirs(repo_path, exist_ok=True)\n        shutil.unpack_archive(archive_path, repo_path)\n        os.remove(archive_path)\n        sol = solver.analyze_issue(problem_statement, repo_path)\n        print(\"sol: \", sol)\n        # Process the issue\n        return sol\n        \n    except Exception as e:\n        print(f\"Error in predict function: {str(e)}\")\n        return None\n    finally:\n        # Clean up\n        if os.path.exists(repo_path):\n            shutil.rmtree(repo_path)\n        #torch.cuda.empty_cache()\n        #gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:38.576720Z","iopub.execute_input":"2025-01-21T12:01:38.576942Z","iopub.status.idle":"2025-01-21T12:01:38.752125Z","shell.execute_reply.started":"2025-01-21T12:01:38.576923Z","shell.execute_reply":"2025-01-21T12:01:38.751213Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"if solver is None:\n    solver = GithubIssueSolver()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:38.752903Z","iopub.execute_input":"2025-01-21T12:01:38.753227Z","iopub.status.idle":"2025-01-21T12:03:20.678956Z","shell.execute_reply.started":"2025-01-21T12:01:38.753203Z","shell.execute_reply":"2025-01-21T12:03:20.678263Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ca356de88e54d53ac5243b175da6064"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"data_t = train_data.sample()\ndata_t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:03:20.679760Z","iopub.execute_input":"2025-01-21T12:03:20.680037Z","iopub.status.idle":"2025-01-21T12:03:20.692017Z","shell.execute_reply.started":"2025-01-21T12:03:20.680008Z","shell.execute_reply":"2025-01-21T12:03:20.691306Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                    instance_id             repo  \\\n5  repo__astropy__astropy-16812  astropy/astropy   \n\n                                   problem_statement  \\\n5  Provide a way to make a copy of a model with d...   \n\n                                               patch  \\\n5  diff --git a/astropy/modeling/core.py b/astrop...   \n\n                                          test_patch  pull_number  \\\n5  diff --git a/astropy/modeling/tests/test_core....        16812   \n\n                                base_commit  \\\n5  c241103c11954d3c1cfe3c1840b1ece72479c522   \n\n                                        PASS_TO_PASS  \\\n5  [astropy/modeling/tests/test_core.py::test_Mod...   \n\n                                        FAIL_TO_PASS issue_numbers  \n5  [astropy/modeling/tests/test_core.py::test_res...       [16593]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instance_id</th>\n      <th>repo</th>\n      <th>problem_statement</th>\n      <th>patch</th>\n      <th>test_patch</th>\n      <th>pull_number</th>\n      <th>base_commit</th>\n      <th>PASS_TO_PASS</th>\n      <th>FAIL_TO_PASS</th>\n      <th>issue_numbers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>repo__astropy__astropy-16812</td>\n      <td>astropy/astropy</td>\n      <td>Provide a way to make a copy of a model with d...</td>\n      <td>diff --git a/astropy/modeling/core.py b/astrop...</td>\n      <td>diff --git a/astropy/modeling/tests/test_core....</td>\n      <td>16812</td>\n      <td>c241103c11954d3c1cfe3c1840b1ece72479c522</td>\n      <td>[astropy/modeling/tests/test_core.py::test_Mod...</td>\n      <td>[astropy/modeling/tests/test_core.py::test_res...</td>\n      <td>[16593]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"repo_name = data_t['instance_id'].values[0]#.replace('/', '_')\nbase_repo_path = \"/kaggle/working/data/repos/\"\n#repo_path = base_repo_path + repo_name\nrepo_path = os.path.join(base_repo_path, repo_name)\nif not os.path.exists(repo_path):\n    raise ValueError(f\"Repository path does not exist: {repo_path}\")\nprint(\"repo_path: \",repo_path)\n# Prepare inputs\nproblem_statement = data_t['problem_statement']\nprint(\"problem_statement: \",problem_statement[:25])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:03:20.692760Z","iopub.execute_input":"2025-01-21T12:03:20.692949Z","iopub.status.idle":"2025-01-21T12:03:20.712291Z","shell.execute_reply.started":"2025-01-21T12:03:20.692933Z","shell.execute_reply":"2025-01-21T12:03:20.711644Z"}},"outputs":[{"name":"stdout","text":"repo_path:  /kaggle/working/data/repos/repo__astropy__astropy-16812\nproblem_statement:  5    Provide a way to make a copy of a model with d...\nName: problem_statement, dtype: object\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(datetime.now().strftime(\"Hour: %H, Minute: %M, Second: %S\")) \nresponse = solver.analyze_issue(\n    problem_statement.values[0],\n    repo_path)\nprint(datetime.now().strftime(\"Hour: %H, Minute: %M, Second: %S\")) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:04:12.987604Z","iopub.execute_input":"2025-01-21T12:04:12.987927Z"}},"outputs":[{"name":"stdout","text":"Hour: 12, Minute: 04, Second: 12\nnum of relevant files 2\nrelevant files ['conftest.py', 'setup.py']\nfile content:  File: conftest.py\n# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\n# This file is the main file used when running tests with pytest directly,\n# in particular if running e.g. ``pytest d\nError generating solution: Tensor on device meta is not on the expected device cuda:0!\nsol:  None\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"#from IPython.display import display, Markdown, Latex\n#display(Markdown(response))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:03:20.724786Z","iopub.execute_input":"2025-01-21T12:03:20.725023Z","iopub.status.idle":"2025-01-21T12:03:20.735701Z","shell.execute_reply.started":"2025-01-21T12:03:20.725004Z","shell.execute_reply":"2025-01-21T12:03:20.735064Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#display(Markdown(data_t['patch'].values[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:03:20.736358Z","iopub.execute_input":"2025-01-21T12:03:20.736542Z","iopub.status.idle":"2025-01-21T12:03:20.749380Z","shell.execute_reply.started":"2025-01-21T12:03:20.736526Z","shell.execute_reply":"2025-01-21T12:03:20.748603Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#cosine_sim = calculate_semantic_similarity(data_t['patch'].values[0], response, model, tokenizer)\n#print(\"Cosine Similarity: \", cosine_sim)#prev: Cosine Similarity:  0.11839781672838229","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:03:20.750071Z","iopub.execute_input":"2025-01-21T12:03:20.750251Z","iopub.status.idle":"2025-01-21T12:03:20.761998Z","shell.execute_reply.started":"2025-01-21T12:03:20.750236Z","shell.execute_reply":"2025-01-21T12:03:20.761336Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"inference_server = kaggle_evaluation.konwinski_prize_inference_server.KPrizeInferenceServer(\n    get_number_of_instances,   \n    predict\n)\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        data_paths=(\n            '/kaggle/input/konwinski-prize/',\n            '/kaggle/tmp/konwinski-prize/',\n        ),\n        use_concurrency=True,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:03:20.762792Z","iopub.execute_input":"2025-01-21T12:03:20.763016Z","iopub.status.idle":"2025-01-21T12:04:02.005301Z","shell.execute_reply.started":"2025-01-21T12:03:20.762989Z","shell.execute_reply":"2025-01-21T12:04:02.003164Z"}},"outputs":[{"name":"stdout","text":"Installing uv...\nInstalling Python 3.11...\n","output_type":"stream"},{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"num of relevant files 2\nrelevant files ['doc/conf.py', 'script/create_contributor_list.py']\nfile content:  File: doc/conf.py\n# Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n# For details: https://github.com/pylint-dev/astroid/blob/main/LICENSE\n# Copyright (c) https://g\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-f59af9d278b5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minference_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     inference_server.run_local_gateway(\n\u001b[0m\u001b[1;32m      9\u001b[0m         data_paths=(\n\u001b[1;32m     10\u001b[0m             \u001b[0;34m'/kaggle/input/konwinski-prize/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/konwinski-prize/kaggle_evaluation/core/templates.py\u001b[0m in \u001b[0;36mrun_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gateway_for_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_share_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/konwinski-prize/kaggle_evaluation/core/templates.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_data_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mkaggle_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGatewayRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/konwinski-prize/kaggle_evaluation/konwinski_prize_gateway.py\u001b[0m in \u001b[0;36mget_all_predictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0menv_setup_cmd_templates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kprize_env_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_env_setup_cmds_templates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_config_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             patch = self.predict(\n\u001b[0m\u001b[1;32m    446\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"problem_statement\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mrepo_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/konwinski-prize/kaggle_evaluation/core/templates.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         '''\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_server_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/konwinski-prize/kaggle_evaluation/core/relay.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         '''\n\u001b[1;32m    276\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_with_deadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/konwinski-prize/kaggle_evaluation/core/relay.py\u001b[0m in \u001b[0;36m_send_with_deadline\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    229\u001b[0m         '''\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_made_first_connection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_deadline_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfirst_call_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":18}]}